{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYVgwkSPGvtT4k6X44zl/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jacquelsn/IA-/blob/https%2Fcolab.research.google.com%2Fdrive%2F1cMPkWtq0mPav13-Sn3uc-BxjSmrcSYLY/IntroducaoColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar o NLTK, basta executar/instanciar um notebook Python"
      ],
      "metadata": {
        "id": "cfxUNbO4MsrF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb4WYOxtG-0i",
        "outputId": "94eca583-e46a-4fac-903b-317c85a853e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.5) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.5) (1.3.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from nltk==3.5) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.5) (4.66.1)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434679 sha256=212b12ebba87c4c6ed72bab3bc1ba90265397cefed90e51de3a809692d6eb1c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/ab/82/f9667f6f884d272670a15382599a9c753a1dfdc83f7412e37d\n",
            "Successfully built nltk\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed nltk-3.5\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk==3.5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O pacote NLTK vem com muitos corpora (conjunto de textos escritos e registros orais em uma determinada língua e que serve como base de análise)"
      ],
      "metadata": {
        "id": "eVT76eLkM5Gd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\timport nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('machado')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V-HTZ1pHy7e",
        "outputId": "647640db-ead9-4865-e973-93d8e65c6ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]   Package machado is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenização e um corpola em português"
      ],
      "metadata": {
        "id": "kgrg1K_jNCkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import machado\n",
        "machado.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM3Y021BH7Xm",
        "outputId": "a9ebfda1-a239-4543-f09f-c7bbb9912ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['contos/macn001.txt',\n",
              " 'contos/macn002.txt',\n",
              " 'contos/macn003.txt',\n",
              " 'contos/macn004.txt',\n",
              " 'contos/macn005.txt',\n",
              " 'contos/macn006.txt',\n",
              " 'contos/macn007.txt',\n",
              " 'contos/macn008.txt',\n",
              " 'contos/macn009.txt',\n",
              " 'contos/macn010.txt',\n",
              " 'contos/macn011.txt',\n",
              " 'contos/macn012.txt',\n",
              " 'contos/macn013.txt',\n",
              " 'contos/macn014.txt',\n",
              " 'contos/macn015.txt',\n",
              " 'contos/macn016.txt',\n",
              " 'contos/macn017.txt',\n",
              " 'contos/macn018.txt',\n",
              " 'contos/macn019.txt',\n",
              " 'contos/macn020.txt',\n",
              " 'contos/macn021.txt',\n",
              " 'contos/macn022.txt',\n",
              " 'contos/macn023.txt',\n",
              " 'contos/macn024.txt',\n",
              " 'contos/macn025.txt',\n",
              " 'contos/macn026.txt',\n",
              " 'contos/macn027.txt',\n",
              " 'contos/macn028.txt',\n",
              " 'contos/macn029.txt',\n",
              " 'contos/macn030.txt',\n",
              " 'contos/macn031.txt',\n",
              " 'contos/macn032.txt',\n",
              " 'contos/macn033.txt',\n",
              " 'contos/macn034.txt',\n",
              " 'contos/macn035.txt',\n",
              " 'contos/macn036.txt',\n",
              " 'contos/macn037.txt',\n",
              " 'contos/macn038.txt',\n",
              " 'contos/macn039.txt',\n",
              " 'contos/macn040.txt',\n",
              " 'contos/macn041.txt',\n",
              " 'contos/macn042.txt',\n",
              " 'contos/macn043.txt',\n",
              " 'contos/macn044.txt',\n",
              " 'contos/macn045.txt',\n",
              " 'contos/macn046.txt',\n",
              " 'contos/macn047.txt',\n",
              " 'contos/macn048.txt',\n",
              " 'contos/macn049.txt',\n",
              " 'contos/macn050.txt',\n",
              " 'contos/macn051.txt',\n",
              " 'contos/macn052.txt',\n",
              " 'contos/macn053.txt',\n",
              " 'contos/macn054.txt',\n",
              " 'contos/macn055.txt',\n",
              " 'contos/macn056.txt',\n",
              " 'contos/macn057.txt',\n",
              " 'contos/macn058.txt',\n",
              " 'contos/macn059.txt',\n",
              " 'contos/macn060.txt',\n",
              " 'contos/macn061.txt',\n",
              " 'contos/macn062.txt',\n",
              " 'contos/macn063.txt',\n",
              " 'contos/macn064.txt',\n",
              " 'contos/macn065.txt',\n",
              " 'contos/macn066.txt',\n",
              " 'contos/macn067.txt',\n",
              " 'contos/macn068.txt',\n",
              " 'contos/macn069.txt',\n",
              " 'contos/macn070.txt',\n",
              " 'contos/macn071.txt',\n",
              " 'contos/macn072.txt',\n",
              " 'contos/macn073.txt',\n",
              " 'contos/macn074.txt',\n",
              " 'contos/macn075.txt',\n",
              " 'contos/macn076.txt',\n",
              " 'contos/macn077.txt',\n",
              " 'contos/macn078.txt',\n",
              " 'contos/macn079.txt',\n",
              " 'contos/macn080.txt',\n",
              " 'contos/macn081.txt',\n",
              " 'contos/macn082.txt',\n",
              " 'contos/macn083.txt',\n",
              " 'contos/macn084.txt',\n",
              " 'contos/macn085.txt',\n",
              " 'contos/macn086.txt',\n",
              " 'contos/macn087.txt',\n",
              " 'contos/macn088.txt',\n",
              " 'contos/macn089.txt',\n",
              " 'contos/macn090.txt',\n",
              " 'contos/macn091.txt',\n",
              " 'contos/macn092.txt',\n",
              " 'contos/macn093.txt',\n",
              " 'contos/macn094.txt',\n",
              " 'contos/macn095.txt',\n",
              " 'contos/macn096.txt',\n",
              " 'contos/macn097.txt',\n",
              " 'contos/macn098.txt',\n",
              " 'contos/macn099.txt',\n",
              " 'contos/macn100.txt',\n",
              " 'contos/macn101.txt',\n",
              " 'contos/macn102.txt',\n",
              " 'contos/macn103.txt',\n",
              " 'contos/macn104.txt',\n",
              " 'contos/macn105.txt',\n",
              " 'contos/macn106.txt',\n",
              " 'contos/macn107.txt',\n",
              " 'contos/macn108.txt',\n",
              " 'contos/macn109.txt',\n",
              " 'contos/macn110.txt',\n",
              " 'contos/macn111.txt',\n",
              " 'contos/macn112.txt',\n",
              " 'contos/macn113.txt',\n",
              " 'contos/macn114.txt',\n",
              " 'contos/macn115.txt',\n",
              " 'contos/macn116.txt',\n",
              " 'contos/macn117.txt',\n",
              " 'contos/macn118.txt',\n",
              " 'contos/macn119.txt',\n",
              " 'contos/macn120.txt',\n",
              " 'contos/macn121.txt',\n",
              " 'contos/macn122.txt',\n",
              " 'contos/macn123.txt',\n",
              " 'contos/macn124.txt',\n",
              " 'contos/macn125.txt',\n",
              " 'contos/macn126.txt',\n",
              " 'contos/macn127.txt',\n",
              " 'contos/macn128.txt',\n",
              " 'contos/macn129.txt',\n",
              " 'contos/macn130.txt',\n",
              " 'contos/macn131.txt',\n",
              " 'contos/macn132.txt',\n",
              " 'contos/macn133.txt',\n",
              " 'contos/macn134.txt',\n",
              " 'contos/macn135.txt',\n",
              " 'contos/macn136.txt',\n",
              " 'contos/macn137.txt',\n",
              " 'critica/mact01.txt',\n",
              " 'critica/mact02.txt',\n",
              " 'critica/mact03.txt',\n",
              " 'critica/mact04.txt',\n",
              " 'critica/mact05.txt',\n",
              " 'critica/mact06.txt',\n",
              " 'critica/mact07.txt',\n",
              " 'critica/mact08.txt',\n",
              " 'critica/mact09.txt',\n",
              " 'critica/mact10.txt',\n",
              " 'critica/mact11.txt',\n",
              " 'critica/mact12.txt',\n",
              " 'critica/mact13.txt',\n",
              " 'critica/mact14.txt',\n",
              " 'critica/mact15.txt',\n",
              " 'critica/mact16.txt',\n",
              " 'critica/mact17.txt',\n",
              " 'critica/mact18.txt',\n",
              " 'critica/mact19.txt',\n",
              " 'critica/mact20.txt',\n",
              " 'critica/mact21.txt',\n",
              " 'critica/mact22.txt',\n",
              " 'critica/mact23.txt',\n",
              " 'critica/mact24.txt',\n",
              " 'critica/mact25.txt',\n",
              " 'critica/mact26.txt',\n",
              " 'critica/mact27.txt',\n",
              " 'critica/mact28.txt',\n",
              " 'critica/mact29.txt',\n",
              " 'critica/mact30.txt',\n",
              " 'critica/mact31.txt',\n",
              " 'critica/mact32.txt',\n",
              " 'critica/mact33.txt',\n",
              " 'critica/mact34.txt',\n",
              " 'critica/mact35.txt',\n",
              " 'critica/mact36.txt',\n",
              " 'critica/mact37.txt',\n",
              " 'critica/mact38.txt',\n",
              " 'critica/mact39.txt',\n",
              " 'critica/mact40.txt',\n",
              " 'critica/mact41.txt',\n",
              " 'critica/mact42.txt',\n",
              " 'critica/mact43.txt',\n",
              " 'critica/mact44.txt',\n",
              " 'critica/mact45.txt',\n",
              " 'cronica/macr01.txt',\n",
              " 'cronica/macr02.txt',\n",
              " 'cronica/macr03.txt',\n",
              " 'cronica/macr04.txt',\n",
              " 'cronica/macr05.txt',\n",
              " 'cronica/macr06.txt',\n",
              " 'cronica/macr07.txt',\n",
              " 'cronica/macr08.txt',\n",
              " 'cronica/macr09.txt',\n",
              " 'cronica/macr10.txt',\n",
              " 'cronica/macr11.txt',\n",
              " 'cronica/macr12.txt',\n",
              " 'cronica/macr13.txt',\n",
              " 'cronica/macr14.txt',\n",
              " 'cronica/macr15.txt',\n",
              " 'cronica/macr16.txt',\n",
              " 'cronica/macr17.txt',\n",
              " 'cronica/macr18.txt',\n",
              " 'cronica/macr19.txt',\n",
              " 'cronica/macr20.txt',\n",
              " 'cronica/macr21.txt',\n",
              " 'cronica/macr22.txt',\n",
              " 'cronica/macr23.txt',\n",
              " 'cronica/macr24.txt',\n",
              " 'miscelanea/mams01.txt',\n",
              " 'miscelanea/mams02.txt',\n",
              " 'miscelanea/mams03.txt',\n",
              " 'miscelanea/mams04.txt',\n",
              " 'miscelanea/mams05.txt',\n",
              " 'miscelanea/mams06.txt',\n",
              " 'miscelanea/mams07.txt',\n",
              " 'miscelanea/mams08.txt',\n",
              " 'miscelanea/mams09.txt',\n",
              " 'miscelanea/mams10.txt',\n",
              " 'poesia/maps01.txt',\n",
              " 'poesia/maps02.txt',\n",
              " 'poesia/maps03.txt',\n",
              " 'poesia/maps04.txt',\n",
              " 'poesia/maps05.txt',\n",
              " 'poesia/maps06.txt',\n",
              " 'poesia/maps07.txt',\n",
              " 'romance/marm01.txt',\n",
              " 'romance/marm02.txt',\n",
              " 'romance/marm03.txt',\n",
              " 'romance/marm04.txt',\n",
              " 'romance/marm05.txt',\n",
              " 'romance/marm06.txt',\n",
              " 'romance/marm07.txt',\n",
              " 'romance/marm08.txt',\n",
              " 'romance/marm09.txt',\n",
              " 'romance/marm10.txt',\n",
              " 'teatro/matt01.txt',\n",
              " 'teatro/matt02.txt',\n",
              " 'teatro/matt03.txt',\n",
              " 'teatro/matt04.txt',\n",
              " 'teatro/matt05.txt',\n",
              " 'teatro/matt06.txt',\n",
              " 'teatro/matt07.txt',\n",
              " 'teatro/matt08.txt',\n",
              " 'teatro/matt09.txt',\n",
              " 'teatro/matt10.txt',\n",
              " 'traducao/matr01.txt',\n",
              " 'traducao/matr02.txt',\n",
              " 'traducao/matr03.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texto = machado.raw('romance/marm05.txt')\n",
        "texto = texto[10082:10954].replace('\\n',' ')\n",
        "texto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "kqOU5_spICOl",
        "outputId": "359b7a95-ff7e-4b01-83f8-68dc1cdc34f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto de Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da África, em prêmio da façanha que praticou, arrebatando trezentas cubas aos mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor, Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções de tokenização para o texto"
      ],
      "metadata": {
        "id": "ctnXzoYPNWIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\tfrom nltk.tokenize import sent_tokenize\n",
        "sentencas = sent_tokenize(texto, language='portuguese')\n",
        "for i,sent in enumerate(sentencas):\n",
        "     print(i,'-',sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dN0ygYw0IEBd",
        "outputId": "64d92cca-7a27-42ac-effa-ecc6b4c09e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto de Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da África, em prêmio da façanha que praticou, arrebatando trezentas cubas aos mouros.\n",
            "1 - Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour.\n",
            "2 - Era um bom caráter, meu pai, varão digno e leal como poucos.\n",
            "3 - Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo?\n",
            "4 - Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor, Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás.\n",
            "5 - Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "palavras = word_tokenize(texto, language='portuguese')\n",
        "print(palavras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF-c6fSJJABw",
        "outputId": "4a31dc10-e529-4d5b-a5cb-884e9e1449fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Como', 'este', 'apelido', 'de', 'Cubas', 'lhe', 'cheirasse', 'excessivamente', 'a', 'tanoaria', ',', 'alegava', 'meu', 'pai', ',', 'bisneto', 'de', 'Damião', ',', 'que', 'o', 'dito', 'apelido', 'fora', 'dado', 'a', 'um', 'cavaleiro', ',', 'herói', 'nas', 'jornadas', 'da', 'África', ',', 'em', 'prêmio', 'da', 'façanha', 'que', 'praticou', ',', 'arrebatando', 'trezentas', 'cubas', 'aos', 'mouros', '.', 'Meu', 'pai', 'era', 'homem', 'de', 'imaginação', ';', 'escapou', 'à', 'tanoaria', 'nas', 'asas', 'de', 'um', 'calembour', '.', 'Era', 'um', 'bom', 'caráter', ',', 'meu', 'pai', ',', 'varão', 'digno', 'e', 'leal', 'como', 'poucos', '.', 'Tinha', ',', 'é', 'verdade', ',', 'uns', 'fumos', 'de', 'pacholice', ';', 'mas', 'quem', 'não', 'é', 'um', 'pouco', 'pachola', 'nesse', 'mundo', '?', 'Releva', 'notar', 'que', 'ele', 'não', 'recorreu', 'à', 'inventiva', 'senão', 'depois', 'de', 'experimentar', 'a', 'falsificação', ';', 'primeiramente', ',', 'entroncou-se', 'na', 'família', 'daquele', 'meu', 'famoso', 'homônimo', ',', 'o', 'capitão-mor', ',', 'Brás', 'Cubas', ',', 'que', 'fundou', 'a', 'vila', 'de', 'São', 'Vicente', ',', 'onde', 'morreu', 'em', '1592', ',', 'e', 'por', 'esse', 'motivo', 'é', 'que', 'me', 'deu', 'o', 'nome', 'de', 'Brás', '.', 'Opôs-se-lhe', ',', 'porém', ',', 'a', 'família', 'do', 'capitão-mor', ',', 'e', 'foi', 'então', 'que', 'ele', 'imaginou', 'as', 'trezentas', 'cubas', 'mouriscas', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "sentencas = sent_tokenize(texto, language='portuguese')\n",
        "for i,sent in enumerate(sentencas):\n",
        "     print(i,'-',word_tokenize(sent, language='portuguese'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVRWnW2qJFxz",
        "outputId": "b9614c2a-bec3-4a92-eb53-d7ea9e65f802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - ['Como', 'este', 'apelido', 'de', 'Cubas', 'lhe', 'cheirasse', 'excessivamente', 'a', 'tanoaria', ',', 'alegava', 'meu', 'pai', ',', 'bisneto', 'de', 'Damião', ',', 'que', 'o', 'dito', 'apelido', 'fora', 'dado', 'a', 'um', 'cavaleiro', ',', 'herói', 'nas', 'jornadas', 'da', 'África', ',', 'em', 'prêmio', 'da', 'façanha', 'que', 'praticou', ',', 'arrebatando', 'trezentas', 'cubas', 'aos', 'mouros', '.']\n",
            "1 - ['Meu', 'pai', 'era', 'homem', 'de', 'imaginação', ';', 'escapou', 'à', 'tanoaria', 'nas', 'asas', 'de', 'um', 'calembour', '.']\n",
            "2 - ['Era', 'um', 'bom', 'caráter', ',', 'meu', 'pai', ',', 'varão', 'digno', 'e', 'leal', 'como', 'poucos', '.']\n",
            "3 - ['Tinha', ',', 'é', 'verdade', ',', 'uns', 'fumos', 'de', 'pacholice', ';', 'mas', 'quem', 'não', 'é', 'um', 'pouco', 'pachola', 'nesse', 'mundo', '?']\n",
            "4 - ['Releva', 'notar', 'que', 'ele', 'não', 'recorreu', 'à', 'inventiva', 'senão', 'depois', 'de', 'experimentar', 'a', 'falsificação', ';', 'primeiramente', ',', 'entroncou-se', 'na', 'família', 'daquele', 'meu', 'famoso', 'homônimo', ',', 'o', 'capitão-mor', ',', 'Brás', 'Cubas', ',', 'que', 'fundou', 'a', 'vila', 'de', 'São', 'Vicente', ',', 'onde', 'morreu', 'em', '1592', ',', 'e', 'por', 'esse', 'motivo', 'é', 'que', 'me', 'deu', 'o', 'nome', 'de', 'Brás', '.']\n",
            "5 - ['Opôs-se-lhe', ',', 'porém', ',', 'a', 'família', 'do', 'capitão-mor', ',', 'e', 'foi', 'então', 'que', 'ele', 'imaginou', 'as', 'trezentas', 'cubas', 'mouriscas', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "punctuations = string.punctuation\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "sentencas = sent_tokenize(texto, language='portuguese')\n",
        "for i,sent in enumerate(sentencas):\n",
        "    sent_sem_pontuacao = [i for i in word_tokenize(sent, language='portuguese') if i not in punctuations]\n",
        "    print(i,'-',sent_sem_pontuacao)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJCPixmiKW65",
        "outputId": "1943b984-6f64-4433-b13e-c368f9364ba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - ['Como', 'este', 'apelido', 'de', 'Cubas', 'lhe', 'cheirasse', 'excessivamente', 'a', 'tanoaria', 'alegava', 'meu', 'pai', 'bisneto', 'de', 'Damião', 'que', 'o', 'dito', 'apelido', 'fora', 'dado', 'a', 'um', 'cavaleiro', 'herói', 'nas', 'jornadas', 'da', 'África', 'em', 'prêmio', 'da', 'façanha', 'que', 'praticou', 'arrebatando', 'trezentas', 'cubas', 'aos', 'mouros']\n",
            "1 - ['Meu', 'pai', 'era', 'homem', 'de', 'imaginação', 'escapou', 'à', 'tanoaria', 'nas', 'asas', 'de', 'um', 'calembour']\n",
            "2 - ['Era', 'um', 'bom', 'caráter', 'meu', 'pai', 'varão', 'digno', 'e', 'leal', 'como', 'poucos']\n",
            "3 - ['Tinha', 'é', 'verdade', 'uns', 'fumos', 'de', 'pacholice', 'mas', 'quem', 'não', 'é', 'um', 'pouco', 'pachola', 'nesse', 'mundo']\n",
            "4 - ['Releva', 'notar', 'que', 'ele', 'não', 'recorreu', 'à', 'inventiva', 'senão', 'depois', 'de', 'experimentar', 'a', 'falsificação', 'primeiramente', 'entroncou-se', 'na', 'família', 'daquele', 'meu', 'famoso', 'homônimo', 'o', 'capitão-mor', 'Brás', 'Cubas', 'que', 'fundou', 'a', 'vila', 'de', 'São', 'Vicente', 'onde', 'morreu', 'em', '1592', 'e', 'por', 'esse', 'motivo', 'é', 'que', 'me', 'deu', 'o', 'nome', 'de', 'Brás']\n",
            "5 - ['Opôs-se-lhe', 'porém', 'a', 'família', 'do', 'capitão-mor', 'e', 'foi', 'então', 'que', 'ele', 'imaginou', 'as', 'trezentas', 'cubas', 'mouriscas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\tstopwords = nltk.corpus.stopwords.words('portuguese')\n",
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lK1woLJLdVZ",
        "outputId": "6153fcd6-dfa7-4cd4-b946-4826d677edd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remoção de pontuações e stop words"
      ],
      "metadata": {
        "id": "Emud8XSNMeAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "sentencas = sent_tokenize(texto, language='portuguese')\n",
        "for i,sent in enumerate(sentencas):\n",
        "    sent_sem_pontuacao = [i for i in word_tokenize(sent, language='portuguese') if i not in punctuations]\n",
        "    sent_sem_stopwords = [i for i in sent_sem_pontuacao if i not in stopwords]\n",
        "    print(i,'-',sent_sem_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOb7c7MqLyL3",
        "outputId": "56403e72-09d9-47e6-d3f6-1d29940ed2f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 - ['Como', 'apelido', 'Cubas', 'cheirasse', 'excessivamente', 'tanoaria', 'alegava', 'pai', 'bisneto', 'Damião', 'dito', 'apelido', 'dado', 'cavaleiro', 'herói', 'jornadas', 'África', 'prêmio', 'façanha', 'praticou', 'arrebatando', 'trezentas', 'cubas', 'mouros']\n",
            "1 - ['Meu', 'pai', 'homem', 'imaginação', 'escapou', 'tanoaria', 'asas', 'calembour']\n",
            "2 - ['Era', 'bom', 'caráter', 'pai', 'varão', 'digno', 'leal', 'poucos']\n",
            "3 - ['Tinha', 'verdade', 'uns', 'fumos', 'pacholice', 'pouco', 'pachola', 'nesse', 'mundo']\n",
            "4 - ['Releva', 'notar', 'recorreu', 'inventiva', 'senão', 'experimentar', 'falsificação', 'primeiramente', 'entroncou-se', 'família', 'daquele', 'famoso', 'homônimo', 'capitão-mor', 'Brás', 'Cubas', 'fundou', 'vila', 'São', 'Vicente', 'onde', 'morreu', '1592', 'motivo', 'deu', 'nome', 'Brás']\n",
            "5 - ['Opôs-se-lhe', 'porém', 'família', 'capitão-mor', 'então', 'imaginou', 'trezentas', 'cubas', 'mouriscas']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag-of-Words (BoW)\n",
        "\n",
        "Criar um BoW para as cinco sentenças que extraímos anteriormente:"
      ],
      "metadata": {
        "id": "P3TXKxu9MKC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\tfrom sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,1))\n",
        "bow = cv.fit_transform(sentencas)\n",
        "print('BoW Shape:',bow.shape)\n",
        "print('BoW Vocabulário (',len(cv.vocabulary_),'palavras ):',cv.vocabulary_)\n",
        "print('Primeira sentença:',bow[0].toarray())\n",
        "print('Segunda sentença:',bow[1].toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMld-neOMNcs",
        "outputId": "84a41af9-be13-4380-89b9-d6d9d6cc26e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BoW Shape: (6, 79)\n",
            "BoW Vocabulário ( 79 palavras ): {'este': 27, 'apelido': 3, 'cheirasse': 13, 'excessivamente': 28, 'alegava': 1, 'bisneto': 7, 'damião': 16, 'dito': 21, 'fora': 34, 'dado': 15, 'cavaleiro': 12, 'herói': 37, 'jornadas': 43, 'da': 14, 'áfrica': 78, 'prêmio': 66, 'façanha': 32, 'praticou': 64, 'arrebatando': 4, 'aos': 2, 'mouros': 50, 'homem': 38, 'imaginação': 40, 'escapou': 25, 'asas': 6, 'calembour': 10, 'bom': 8, 'caráter': 11, 'varão': 74, 'digno': 20, 'leal': 44, 'poucos': 63, 'tinha': 72, 'verdade': 75, 'uns': 73, 'fumos': 35, 'pacholice': 59, 'mas': 45, 'quem': 67, 'pouco': 62, 'pachola': 58, 'nesse': 53, 'mundo': 51, 'releva': 69, 'notar': 55, 'recorreu': 68, 'inventiva': 42, 'senão': 70, 'depois': 18, 'experimentar': 29, 'falsificação': 30, 'primeiramente': 65, 'entroncou': 23, 'na': 52, 'daquele': 17, 'famoso': 31, 'homônimo': 39, 'brás': 9, 'fundou': 36, 'vila': 77, 'são': 71, 'vicente': 76, 'onde': 56, 'morreu': 47, '1592': 0, 'por': 60, 'esse': 26, 'motivo': 48, 'me': 46, 'deu': 19, 'nome': 54, 'opôs': 57, 'porém': 61, 'do': 22, 'foi': 33, 'então': 24, 'imaginou': 41, 'as': 5, 'mouriscas': 49}\n",
            "Primeira sentença: [[0 1 1 2 1 0 0 1 0 0 0 0 1 1 2 1 1 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 1 0 1 0\n",
            "  0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0\n",
            "  0 0 0 0 0 0 1]]\n",
            "Segunda sentença: [[0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    }
  ]
}